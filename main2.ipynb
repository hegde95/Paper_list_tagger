{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/miniconda3/envs/tag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/papers.csv\")\n",
    "# data = data[data[\"Abstract\"].notna()]\n",
    "\n",
    "# add a ai_generated_tag column\n",
    "data[\"ai_generated_Methods_tag\"] = \"\"\n",
    "data[\"ai_generated_Highlevel_tag\"] = \"\"\n",
    "data[\"ai_generated_Morphologies_tag\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Methods_tags_dict = {\n",
    "\"Deep reinforcement learning is a machine learning approach that combines deep neural networks with reinforcement learning (RL) algorithms to enable agents to learn optimal actions through trial and error in complex environments. This paper trains a deep reinforcement learning policy for a task.\":\"Deep reinforcement learning\",\n",
    "\n",
    "\"Informative path planning is a robotics and AI technique that aims to find optimal paths for agents or vehicles by considering the most informative locations or viewpoints along the way to gather valuable data or observations.\":\"Informative path planning\",\n",
    "\n",
    "\"Simulation is the imitation or emulation of the operation of a real-world process or system over time, allowing for analysis, testing, and understanding of its behavior without directly interacting with the actual system. This paper proposes a method to model systems to provide better simulations. We showcase our simulation.\":\"Simulation\",\n",
    "\n",
    "# \"By learning the parameters of the simulator, we aim to improve the accuracy of simulations so that they closely match real-world dynamics, which is crucial for the development of control and perception methods in robotics. \": \"Learning for simulation\",\n",
    "\n",
    "\"Localization in robotics refers to the process of determining a robot's precise position and orientation within its environment, typically using sensors and mapping techniques to navigate and perform tasks accurately.\":\"Localization\",\n",
    "\n",
    "\"Mapping in robotics refers to the process of creating a spatial representation of an environment using sensors and data, enabling a robot to understand and navigate its surroundings.\":\"Mapping\",\n",
    "\n",
    "\"simultaneous localization and mapping is a computational technique used in robotics to enable a robot to build a map of its environment while simultaneously determining its own position within that map in real-time.\":\"SLAM\",\n",
    "\n",
    "\"Multi robot simultaneous localization and mapping in robotics is the collaborative process where multiple robots work together to create a map of their environment while simultaneously determining their own positions within that map.\":\"Multi-robot SLAM\",\n",
    "\n",
    "\"Multi robot coordination and planning in robotics refers to the process of enabling multiple robots to work together efficiently and collaboratively to achieve common goals by optimizing their actions and movements in a coordinated manner.\":\"Multi-robot coordination and planning\",\n",
    "\n",
    "\"Deformable manipulation in robotics refers to the capability of a robot to interact with and manipulate objects that have flexible or deformable properties, such as textiles or soft materials, by adapting its grasp and manipulation strategies to accommodate their changing shapes.\":\"Deformable manipulation\",\n",
    "\n",
    "\"Learning from demonstrations in robotics is a process where a robot acquires new skills or behaviors by observing and imitating human or expert demonstrations.\":\"Learning from demonstrations\",\n",
    "\n",
    "\"Motion planning in robotics is the process of determining a sequence of feasible movements for a robot to navigate from its current position to a desired goal while avoiding obstacles and adhering to constraints.\":\"Motion planning\",\n",
    "\n",
    "\"Meta learning in robotics and machine learning is a technique where a model learns how to learn, enabling it to adapt and generalize to new tasks or environments more efficiently by leveraging prior learning experiences.\":\"Meta learning\",\n",
    "}\n",
    "\n",
    "all_method_tags = list(all_Methods_tags_dict.keys())\n",
    "method_tags_embeddings = sentence_transformer_model.encode(all_method_tags, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Highlevel_tags_dict = {\n",
    "    \"This paper proposes a learning based method. Learning in robotics refers to the ability of a robot or robotic system to acquire knowledge, adapt to its environment, and improve its performance over time through various methods such as machine learning, reinforcement learning, or other artificial intelligence techniques. This can involve tasks like recognizing objects, understanding speech, or navigating unfamiliar terrain by learning from past experiences or data.\": \"Learning\",\n",
    "    \"This paper proposes a planning method. Planning in robotics involves the process of generating a sequence of actions or a trajectory that a robot should follow to achieve a specific goal or task. This can include path planning (finding the best route from one point to another), motion planning (determining how to move robot joints or actuators to reach a desired configuration), or task planning (sequencing a series of actions to complete a complex task efficiently).\": \"Planning\",\n",
    "    \"This paper proposes a novel control algorithm. Control in robotics is the mechanism or set of algorithms that enable a robot to manipulate its actuators (such as motors or servos) to achieve desired movements or behaviors. This involves regulating the robot's state, ensuring it follows a prescribed path or trajectory, and reacting to disturbances in its environment to maintain stability and accuracy. Control can be open-loop (predefined actions) or closed-loop (responsive to feedback).\": \"Control\",\n",
    "    \"Our methods propose novel dynamics for systems. Dynamics in robotics refers to the study of the motion and forces involved in the movement of a robot or its components. This includes understanding how forces and torques affect the robot's motion and how the robot's mass, inertia, and geometry influence its behavior. Dynamics plays a crucial role in tasks such as robot design, motion planning, and control, as it helps predict and model how a robot will respond to different inputs and external forces.\": \"Dynamics\",\n",
    "}\n",
    "all_highlevel_tags = list(all_Highlevel_tags_dict.keys())\n",
    "highlevel_tags_embeddings = sentence_transformer_model.encode(all_highlevel_tags, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Morphologies_tags_dict = {\n",
    "    \"Aquatic robots have a morphology designed for operation in water environments. They are typically equipped with features such as buoyancy control, underwater propulsion systems (e.g., fins, propellers), and sensors suited for underwater navigation and data collection. Aquatic robots can include submersibles, underwater drones, and remotely operated vehicles (ROVs), among others..\": \"Aquatic\",\n",
    "    \"Aerial UAVs have a morphology optimized for flying in the air. They are characterized by their wings, rotors, or other means of generating lift and control. Aerial UAVs are used for various applications, including surveillance, aerial photography, mapping, and environmental monitoring.\": \"Aerial UAVs\",\n",
    "    \"Ground robots are designed to operate on the terrestrial surface, such as roads, rough terrain, or indoor environments. They typically have wheels, tracks, or legs for mobility, and their sensors and control systems are tailored for ground-based tasks. Examples of ground robots include autonomous cars, robotic vacuum cleaners, and search-and-rescue robots.\": \"Ground\",\n",
    "    \"Robots with manipulator arms have a morphology that includes one or more articulated arms equipped with joints, end-effectors (such as grippers or tools), and sensors. These robots are designed for tasks that require precise manipulation, such as pick-and-place operations, assembly, and handling objects in unstructured environments.\": \"Manipulator Arms\",\n",
    "    \"Mobile manipulator arms combine the features of both mobile platforms (wheels, tracks, or legs for movement) and manipulator arms. They are capable of navigating in their environment while also performing manipulation tasks. Mobile manipulator arms are versatile and can be used in applications like warehouse automation, agriculture, and disaster response.\": \"Mobile Manipulator Arms\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n",
      "No method tags found for this paper\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.2\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    abstract = row[\"Abstract\"]\n",
    "    if pd.isna(abstract):\n",
    "        continue\n",
    "\n",
    "    # abstract_sentences = abstract.split(\".\")\n",
    "    abstract_sentences = [abstract]\n",
    "\n",
    "    # Compute embedding for both abstract and tags\n",
    "    abstract_embedding = sentence_transformer_model.encode(abstract_sentences, convert_to_tensor=True)\n",
    "\n",
    "    method_cosine_scores = util.dot_score(method_tags_embeddings, abstract_embedding)\n",
    "    highlevel_cosine_scores = util.dot_score(highlevel_tags_embeddings, abstract_embedding)\n",
    "    \n",
    "\n",
    "    # cosine_scores = cosine_scores.max(1).values\n",
    "    method_cosine_scores = method_cosine_scores.mean(1)\n",
    "    # Sort the scores for tags\n",
    "    sorted_indices = method_cosine_scores.argsort(descending=True)\n",
    "    # get the tags with scores above the threshold\n",
    "    sorted_indices = sorted_indices[method_cosine_scores[sorted_indices] > threshold]#[0:1]\n",
    "    # find top tags that stand out\n",
    "    normalized_method_scores = (method_cosine_scores - method_cosine_scores.mean()) / method_cosine_scores.std()\n",
    "    # pick scores that are above 1 standard deviations\n",
    "    sorted_indices = sorted_indices[normalized_method_scores[sorted_indices] > 1]\n",
    "    top_5_method_tags_dict = {all_Methods_tags_dict[all_method_tags[idx]]: str(normalized_method_scores[idx].item())[:4] for idx in sorted_indices}\n",
    "\n",
    "\n",
    "    highlevel_cosine_scores = highlevel_cosine_scores.mean(1)\n",
    "\n",
    "    # get the tag with the highest score\n",
    "    sorted_indices = highlevel_cosine_scores.argsort(descending=True)[0:1]\n",
    "    # find top tags that stand out\n",
    "    top_highlevel_tag = all_highlevel_tags[sorted_indices[0]]\n",
    "    top_highlevel_score = str(highlevel_cosine_scores[sorted_indices[0]].item())[:4]\n",
    "    top_5_highlevel_tags_dict = {all_Highlevel_tags_dict[top_highlevel_tag]: top_highlevel_score}\n",
    "\n",
    "\n",
    "    title = row[\"Title\"]\n",
    "    # if len(sorted_indices) < 2:\n",
    "        # print(\"here\")\n",
    "    # print(\"\\nTitle: {}: tags: {}\".format(title, top_5_method_tags_dict))\n",
    "\n",
    "    if len(top_5_method_tags_dict) == 0:\n",
    "        print(\"No method tags found for this paper\")\n",
    "        continue\n",
    "    if len(top_5_highlevel_tags_dict) == 0:\n",
    "        print(\"No highlevel tags found for this paper\")\n",
    "        continue\n",
    "\n",
    "    # add the tags to the dataframe\n",
    "    list_of_method_tags = list(top_5_method_tags_dict.keys())\n",
    "    list_of_highlevel_tags = list(top_5_highlevel_tags_dict.keys())\n",
    "    data.at[i, \"ai_generated_Methods_tag\"] = \", \".join(list_of_method_tags)\n",
    "    data.at[i, \"ai_generated_Highlevel_tag\"] = \", \".join(list_of_highlevel_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ai_generated_Methods_tag</th>\n",
       "      <th>ai_generated_Highlevel_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GranularGym: High Performance Simulation for R...</td>\n",
       "      <td>Simulation, Deep reinforcement learning</td>\n",
       "      <td>Dynamics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndustReal: Transferring Contact-Rich Assembly...</td>\n",
       "      <td>Deep reinforcement learning, Learning from dem...</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast and Scalable Signal Inference for Active ...</td>\n",
       "      <td>Informative path planning, Motion planning</td>\n",
       "      <td>Planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Language-Informed Transfer Learning for Embodi...</td>\n",
       "      <td>Deep reinforcement learning, Meta learning</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RREx-BoT: Remote Referring Expressions with a ...</td>\n",
       "      <td>Meta learning</td>\n",
       "      <td>Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>The Design and Control of a Prototype Quadrupe...</td>\n",
       "      <td>Motion planning, Multi-robot coordination and ...</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Mobility evaluation of a wheeled microrover us...</td>\n",
       "      <td>Motion planning, Multi-robot coordination and ...</td>\n",
       "      <td>Planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Mission Reachability for Extraterrestrial Rovers.</td>\n",
       "      <td>Motion planning, Mapping</td>\n",
       "      <td>Planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>On the Development of EMG Control for a Prosth...</td>\n",
       "      <td>Learning from demonstrations, Meta learning</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Control philosophy and simulation of a robotic...</td>\n",
       "      <td>Motion planning, Deformable manipulation</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    GranularGym: High Performance Simulation for R...   \n",
       "1    IndustReal: Transferring Contact-Rich Assembly...   \n",
       "2    Fast and Scalable Signal Inference for Active ...   \n",
       "3    Language-Informed Transfer Learning for Embodi...   \n",
       "4    RREx-BoT: Remote Referring Expressions with a ...   \n",
       "..                                                 ...   \n",
       "462  The Design and Control of a Prototype Quadrupe...   \n",
       "463  Mobility evaluation of a wheeled microrover us...   \n",
       "464  Mission Reachability for Extraterrestrial Rovers.   \n",
       "465  On the Development of EMG Control for a Prosth...   \n",
       "466  Control philosophy and simulation of a robotic...   \n",
       "\n",
       "                              ai_generated_Methods_tag  \\\n",
       "0              Simulation, Deep reinforcement learning   \n",
       "1    Deep reinforcement learning, Learning from dem...   \n",
       "2           Informative path planning, Motion planning   \n",
       "3           Deep reinforcement learning, Meta learning   \n",
       "4                                        Meta learning   \n",
       "..                                                 ...   \n",
       "462  Motion planning, Multi-robot coordination and ...   \n",
       "463  Motion planning, Multi-robot coordination and ...   \n",
       "464                           Motion planning, Mapping   \n",
       "465        Learning from demonstrations, Meta learning   \n",
       "466           Motion planning, Deformable manipulation   \n",
       "\n",
       "    ai_generated_Highlevel_tag  \n",
       "0                     Dynamics  \n",
       "1                     Learning  \n",
       "2                     Planning  \n",
       "3                     Learning  \n",
       "4                     Learning  \n",
       "..                         ...  \n",
       "462                    Control  \n",
       "463                   Planning  \n",
       "464                   Planning  \n",
       "465                    Control  \n",
       "466                    Control  \n",
       "\n",
       "[467 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"Title\", \"ai_generated_Methods_tag\", \"ai_generated_Highlevel_tag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "data.to_csv(\"data/papers_with_ai_tags.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
